apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: test-spark
  namespace: data-stack-dev
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: ojolanki/spark-s3:3.5.3-boto3 
  imagePullPolicy: IfNotPresent
  mainApplicationFile: https://raw.githubusercontent.com/keenangraham/cdk-kubernetes/refs/heads/main/spark/test-spark.py
  sparkVersion: 3.5.3
  driver:
    labels: 
      app.kubernetes.io/name: "test-spark-app"
    coreRequest: "2000m"
    memory: "8192M"
    serviceAccount: spark-bucket-read-sa
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: aws-spark-access-key
            key: ACCESS_KEY
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: aws-spark-secret-access-key
            key: SECRET_ACCESS_KEY
      - name: DATE
        value: "{{ ds }}"
    volumeMounts:
      - name: aws-creds
        mountPath: /tmp/.aws-creds
  volumes:
    - name: aws-creds
      csi:
        driver: secrets-store.csi.k8s.io
        readOnly: true
        volumeAttributes:
          secretProviderClass: "spark-aws-secrets"
  executor:
    coreRequest: "1000m"
    memory: "2048M"
    serviceAccount: spark-bucket-read-sa
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: aws-spark-access-key
            key: ACCESS_KEY
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: aws-spark-secret-access-key
            key: SECRET_ACCESS_KEY
    volumeMounts:
      - name: aws-creds
        mountPath: /tmp/.aws-creds
  volumes:
    - name: aws-creds
      csi:
        driver: secrets-store.csi.k8s.io
        readOnly: true
        volumeAttributes:
          secretProviderClass: "spark-aws-secrets"
  dynamicAllocation:
    enabled: true
    initialExecutors: 1
    maxExecutors: 10
    minExecutors: 1
  sparkConf:
    "spark.hadoop.fs.s3a.bucket.encode-public-logs.aws.credentials.provider": "com.amazonaws.auth.EnvironmentVariableCredentialsProvider"
    "spark.hadoop.fs.s3a.bucket.spark-log-parsing-test.aws.credentials.provider": "com.amazonaws.auth.WebIdentityTokenCredentialsProvider"
    "log4j.logger.org.apache.hadoop.fs.s3a": "DEBUG"
    "log4j.logger.com.amazonaws": "DEBUG"
    "log4j.logger.com.amazonaws.internal": "DEBUG"