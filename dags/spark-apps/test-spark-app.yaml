apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: test-spark
  namespace: data-stack-dev
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: ojolanki/spark-s3:3.5.5-withhadoopaws 
  imagePullPolicy: IfNotPresent
  mainApplicationFile: https://raw.githubusercontent.com/keenangraham/cdk-kubernetes/refs/heads/main/spark/test-spark.py
  sparkVersion: 3.5.5
  driver:
    labels: 
      app.kubernetes.io/name: "test-spark-app"
    coreRequest: "1000m"
    memory: "2048M"
    serviceAccount: spark-bucket-read-sa
  executor:
    coreRequest: "100m"
    memory: "512M"
    serviceAccount: spark-bucket-read-sa
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: aws-spark-access-key
            key: ACCESS_KEY
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: aws-spark-secret-access-key
            key: SECRET_ACCESS_KEY
    volumeMounts:
      - name: aws-creds
        mountPath: /tmp/.aws-creds
  volumes:
    - name: aws-creds
      csi:
        driver: secrets-store.csi.k8s.io
        readOnly: true
        volumeAttributes:
          secretProviderClass: "spark-aws-secrets"
  dynamicAllocation:
    enabled: true
    initialExecutors: 1
    maxExecutors: 5
    minExecutors: 1
  sparkConf:
    "spark.hadoop.fs.s3a.sdk.version": "2"
    "spark.hadoop.fs.s3a.bucket.encode-public-logs.aws.credentials.provider": "software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider"
    "spark.hadoop.fs.s3a.bucket.spark-log-parsing-test.aws.credentials.provider": "software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider"